{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "vo0hdWDrI-xD",
    "outputId": "370b501c-63d5-49f2-8e2c-33a0a7c10b20",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "GOOGLE_DRIVE_MOUNT = \"/content/gdrive\"\n",
    "drive.mount(GOOGLE_DRIVE_MOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "BPHtLDN1JAnl",
    "outputId": "4b4a67c9-d634-4e58-a5a8-dc0b15d7a118"
   },
   "outputs": [],
   "source": [
    "% cd ..\n",
    "! cp -rf '/content/gdrive/My Drive/colab/Frame_Classification' .\n",
    "% cd Frame_Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "colab_type": "code",
    "id": "bMu9b7HjI8ff",
    "outputId": "e7b30146-104c-4a6c-aff8-e59a2c016c11"
   },
   "outputs": [],
   "source": [
    "! pip install wavio\n",
    "! pip install soundfile\n",
    "! pip install nlpaug\n",
    "! pip install keras-metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WS2c4p7iI8fs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from core import read_meta_yaml\n",
    "import wave\n",
    "import contextlib\n",
    "import wavio\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import groupby\n",
    "import librosa\n",
    "import nlpaug.flow as naf\n",
    "import nlpaug.augmenter.spectrogram as nas\n",
    "import nlpaug.augmenter.audio as naa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1YYt0UvJI8f1"
   },
   "outputs": [],
   "source": [
    "WINDOW_WIDTH = 5e-1 #s\n",
    "HOP_LENGTH = 225\n",
    "SAMPLE_RATE = 44100\n",
    "SPECTROGRAM_HEIGH = 129\n",
    "SPECTROGRAM_WIDTH = int(WINDOW_WIDTH * SAMPLE_RATE / HOP_LENGTH)\n",
    "PROB_TRESHOLD = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w4q74u7yI8gA"
   },
   "outputs": [],
   "source": [
    "class_labels = ['clearthroat', 'knock', 'keys', 'bg']\n",
    "NUM_CLASSES = len(class_labels)\n",
    "class_to_idx = {c: idx for idx, c in enumerate(class_labels)}\n",
    "idx_to_class = {class_to_idx[c]: c for c in class_to_idx.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pO6hzzRzI8gE"
   },
   "outputs": [],
   "source": [
    "def create_spectrogram_from_wav_file(wavfile_path, onset, offset):\n",
    "    audio = wavio.read(wavfile_path).data\n",
    "    if audio.shape[1] > 1:\n",
    "        audio = np.sum(audio, axis = 1)\n",
    "    else:\n",
    "        audio = audio.reshape((-1,))\n",
    "    if offset*SAMPLE_RATE > audio.shape[0]:\n",
    "      \n",
    "        old = audio.shape\n",
    "        new = (int(SAMPLE_RATE * WINDOW_WIDTH), )\n",
    "        samples = audio[(np.arange(new[0]) % old[0])]\n",
    "    else:\n",
    "        samples = audio[int(onset*SAMPLE_RATE):int(offset*SAMPLE_RATE)]\n",
    "    frequencies, times, spectrogram = signal.spectrogram(samples, SAMPLE_RATE)\n",
    "#    fig=plt.figure(figsize=((5, 5)))\n",
    "#    ax=fig.add_subplot(1,1,1)\n",
    "#    plt.axis('off')\n",
    "#    plt.pcolormesh(times, frequencies, np.log10(spectrogram+1e-20), figure = fig)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "iqdEjHnbI8gO",
    "outputId": "a3e7a888-d08f-4b3d-82a7-7f1bd8aca991"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bw-xJAd1I8gT"
   },
   "outputs": [],
   "source": [
    "# reset graph when you change architecture!\n",
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xT1t4LL2I8gZ"
   },
   "outputs": [],
   "source": [
    "# import necessary building blocks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, GlobalAveragePooling2D, \\\n",
    "    BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WiZ6buuwI8gf"
   },
   "outputs": [],
   "source": [
    "from keras.metrics import categorical_crossentropy, categorical_accuracy\n",
    "from keras_metrics import precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oq8UPM86I8gn"
   },
   "outputs": [],
   "source": [
    "def make_model2():\n",
    "   \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=2, padding='same', input_shape=(SPECTROGRAM_HEIGH, SPECTROGRAM_WIDTH, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    ############################################################################\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    ############################################################################\n",
    "    \n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), strides=2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=128, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    ############################################################################\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    ############################################################################\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    ############################################################################\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    ############################################################################\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), strides=2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    ############################################################################\n",
    "    \n",
    "    model.add(Conv2D(filters=1024, kernel_size=(3, 3), strides=2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=1024, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    ############################################################################  \n",
    "    \n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    \n",
    "    ############################################################################\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "cgb4vI5eI8g4",
    "outputId": "a5459179-af67-4b77-f965-24777a4925c0"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model2()  # define our model\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0),\n",
    "    metrics=[categorical_accuracy, precision(), recall(), f1_score()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WK1tlSBMI8hC"
   },
   "outputs": [],
   "source": [
    "def test_iterator(batch_size, audio_path):\n",
    "    audio_paths = []\n",
    "    if os.path.isdir(audio_path):\n",
    "        for inp_file in os.listdir(audio_path):\n",
    "            audio_paths += [audio_path + inp_file]\n",
    "    else:\n",
    "        audio_paths += [audio_path] \n",
    "        \n",
    "    audio_paths = [inp_file for inp_file in audio_paths if (inp_file[-4:]  == '.wav')]\n",
    "    \n",
    "    tracks = []\n",
    "\n",
    "    batch_keys = []\n",
    "    batch_data = []\n",
    "    \n",
    "    for j, inp_audio in enumerate(audio_paths):\n",
    "        data = wavio.read(inp_audio).data\n",
    "        \n",
    "        full_segments = (data.shape[0] /  float(SAMPLE_RATE)) // WINDOW_WIDTH\n",
    "        if (data.shape[0] / float(SAMPLE_RATE)) % WINDOW_WIDTH != 0:\n",
    "            full_segments += 1\n",
    "        \n",
    "        segments = []\n",
    "        for i in range(int(full_segments)):\n",
    "            \n",
    "\n",
    "            batch_data.append(create_spectrogram_from_wav_file(inp_audio, i * WINDOW_WIDTH, (i+1)*WINDOW_WIDTH))\n",
    "            batch_keys.append((inp_audio,i))\n",
    "            if len(batch_data) == batch_size:\n",
    "                \n",
    "                batch_data = np.stack(batch_data, axis=0)\n",
    "                batch_data = np.expand_dims(batch_data, -1)\n",
    "                batch_data = batch_data.astype('float32')\n",
    "                batch_data = batch_data +  1e-21\n",
    "                batch_data = np.log10(batch_data)\n",
    "                batch_data =  (((batch_data - np.min(batch_data)) * (1 - (-1))) / float(np.max(batch_data) - np.min(batch_data))) + (-1)\n",
    "              \n",
    "                yield batch_keys, batch_data\n",
    "                batch_keys = []\n",
    "                batch_data = []    \n",
    "   \n",
    "    if batch_data:  # last batch\n",
    "        batch_data = np.stack(batch_data, axis=0)\n",
    "        batch_data = np.expand_dims(batch_data, -1)\n",
    "        batch_data = batch_data.astype('float32')\n",
    "       \n",
    "        batch_data = batch_data +  1e-21\n",
    "        batch_data = np.log10(batch_data)\n",
    "        batch_data =  (((batch_data - np.min(batch_data)) * (1 - (-1))) / float(np.max(batch_data) - np.min(batch_data))) + (-1)\n",
    "\n",
    "        yield batch_keys, batch_data\n",
    "        batch_keys = []\n",
    "        batch_data = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "07Qgv5umI8hL"
   },
   "outputs": [],
   "source": [
    "def predict(audio_path = './test_audio_folder/'):\n",
    "    colors = ['r', 'g', 'b', 'y']\n",
    "    \n",
    "    keys = []\n",
    "    classes = []\n",
    "    \n",
    "    for batch_keys, batch_data in test_iterator(BATCH_SIZE, audio_path):\n",
    "        keys.append(batch_keys)\n",
    "        probs = model.predict_proba(batch_data, BATCH_SIZE)\n",
    "        prob_argmax = np.argmax(probs, axis=1)\n",
    "        print(prob_argmax)\n",
    "        prob_max = np.max(probs, axis=1)\n",
    "        cs = [c if prob_max[i] > PROB_TRESHOLD else class_to_idx['bg'] for i,c in enumerate(prob_argmax)]\n",
    "        classes.append(cs)\n",
    "\n",
    "    classes = [c for batch in classes for c in batch]\n",
    "    keys = [k for batch in keys for k in batch]\n",
    "    \n",
    "    keys_classes = list(zip(keys, classes))\n",
    "    \n",
    "    keys_classes.sort(key = lambda x : (x[0][0], x[0][1]))\n",
    "    files = [list(g) for k, g in groupby(keys_classes, lambda s: s[0][0].partition('/')[-1])]\n",
    "    for f in files:\n",
    "        filename = f[0][0][0]\n",
    "        window_classes = [i[1] for i in f]\n",
    "        \n",
    "        audio = wavio.read(filename).data\n",
    "        if audio.shape[1] > 1:\n",
    "            audio = np.sum(audio, axis = 1)\n",
    "        else:\n",
    "            audio = audio.reshape((-1,))\n",
    "\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.title(filename)\n",
    "        plt.plot(np.linspace(0, audio.shape[0], audio.shape[0]), audio)\n",
    "        \n",
    "        for i, window in enumerate(window_classes):\n",
    "            lb = int(i * WINDOW_WIDTH * SAMPLE_RATE)\n",
    "            rb = int(min(audio.shape[0], (i+1) * WINDOW_WIDTH * SAMPLE_RATE))\n",
    "        \n",
    "            plt.plot(np.linspace(0, audio.shape[0], audio.shape[0])[lb:rb], audio[lb:rb], label = idx_to_class[window], c = colors[window])\n",
    "        \n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        newLabels, newHandles = [], []\n",
    "        for handle, label in zip(handles, labels):\n",
    "            if label not in newLabels:\n",
    "                newLabels.append(label)\n",
    "                newHandles.append(handle)\n",
    "        plt.legend(newHandles, newLabels)\n",
    "        plt.xlabel('time (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bBgnvsooI8hb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('model')\n",
    "predict('./test_audio_folder/')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Test.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
