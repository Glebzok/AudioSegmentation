{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "voeQk_2iYpP_"
   },
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BZDtlKAYY3Wo"
   },
   "source": [
    "## Prepare GoogleDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "8IXi976QY2jd",
    "outputId": "31adc194-bd16-412a-98ec-06e5c53d3fe1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "GOOGLE_DRIVE_MOUNT = \"/content/gdrive\"\n",
    "drive.mount(GOOGLE_DRIVE_MOUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "tTOIwpdtY6VD",
    "outputId": "7fface09-1bcc-4306-f85b-54707df41c3f"
   },
   "outputs": [],
   "source": [
    "% cd ..\n",
    "! cp -rf '/content/gdrive/My Drive/colab/Frame_Classification' .\n",
    "% cd Frame_Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "colab_type": "code",
    "id": "NSfGNp3AYpQC",
    "outputId": "3ad3325f-2d0b-4b8b-ebd6-fd4e7b8501ba"
   },
   "outputs": [],
   "source": [
    "! pip install wavio\n",
    "! pip install soundfile\n",
    "! pip install nlpaug\n",
    "! pip install keras-metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XgexSatOYpQH"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMv09gNnYpQJ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from core import read_meta_yaml\n",
    "import wave\n",
    "import contextlib\n",
    "import wavio\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import groupby\n",
    "import librosa\n",
    "import nlpaug.flow as naf\n",
    "import nlpaug.augmenter.spectrogram as nas\n",
    "import nlpaug.augmenter.audio as naa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OUxoQDgSYpQa"
   },
   "source": [
    "## Env Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DRdCnWNvYpQc"
   },
   "outputs": [],
   "source": [
    "train_events_folder = './audio_data/train/events'\n",
    "train_bgs_folder = './audio_data/train/bgs/audio'\n",
    "train_events_meta_folder = './audio_data/train/cv_setup/events_evaltest.yaml'\n",
    "\n",
    "val_events_folder = './audio_data/val/events'\n",
    "val_bgs_folder = './audio_data/val/bgs/audio'\n",
    "val_events_meta_folder = './audio_data/val/cv_setup/events_evaltest.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gwJ0_OyOYpQg"
   },
   "outputs": [],
   "source": [
    "WINDOW_WIDTH = 5e-1 #s\n",
    "HOP_LENGTH = 225\n",
    "SAMPLE_RATE = 44100\n",
    "SPECTROGRAM_HEIGH = 129\n",
    "SPECTROGRAM_WIDTH = int(WINDOW_WIDTH * SAMPLE_RATE / HOP_LENGTH)\n",
    "MASK_FACTOR = 40\n",
    "NMB_OF_GENERATED_IMG_PER_IMG = 1\n",
    "PROB_TRESHOLD = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IIcP1xJYpQl"
   },
   "source": [
    "## Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "7qjqlH_2YpQn",
    "outputId": "fafe077e-ce42-4e57-ab67-6f631280e4eb"
   },
   "outputs": [],
   "source": [
    "class_labels = os.listdir(train_events_folder) + ['bg']\n",
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "18UJPzb2YpQt",
    "outputId": "efa31398-2834-45d0-e70d-399723a253d0"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = len(class_labels)\n",
    "class_to_idx = {c: idx for idx, c in enumerate(class_labels)}\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "G-PQxLro90oT",
    "outputId": "7624b78d-f3cf-40ab-f6d2-8cd82fda77e0"
   },
   "outputs": [],
   "source": [
    "idx_to_class = {class_to_idx[c]: c for c in class_to_idx.keys()}\n",
    "idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gku3kPdwYpQ0"
   },
   "outputs": [],
   "source": [
    "def get_duration(wav_file_name):\n",
    "    with contextlib.closing(wave.open(wav_file_name,'r')) as f:\n",
    "        frames = f.getnframes()\n",
    "        rate = f.getframerate()\n",
    "        duration = frames / float(rate)\n",
    "        return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TplSLWnNYpQ6"
   },
   "outputs": [],
   "source": [
    "def get_one_class_generator(class_name, phase = 'train', debug=False):\n",
    "    if phase == 'train':\n",
    "        bgs_folder = train_bgs_folder\n",
    "        events_folder = train_events_folder\n",
    "        events_meta_folder = train_events_meta_folder\n",
    "    else:\n",
    "        bgs_folder = val_bgs_folder\n",
    "        events_folder = val_events_folder\n",
    "        events_meta_folder = val_events_meta_folder\n",
    "      \n",
    "    while True:\n",
    "        if class_name == 'bg':\n",
    "            for file in os.listdir(bgs_folder):\n",
    "                duration = get_duration(bgs_folder+'/'+file)\n",
    "                \n",
    "                if duration < WINDOW_WIDTH:\n",
    "                    continue\n",
    "                \n",
    "                onset = np.random.random(1) * (duration - WINDOW_WIDTH)\n",
    "                offset = onset + WINDOW_WIDTH\n",
    "                yield class_name, bgs_folder+'/'+file, float(onset), float(offset)\n",
    "                \n",
    "            if debug:\n",
    "                print(class_name, \"is done, starting from the beginning...\")\n",
    "        else:\n",
    "            for file in read_meta_yaml(events_meta_folder)[class_name]:\n",
    "                \n",
    "                if file['segment'][1] - file['segment'][0] < WINDOW_WIDTH:\n",
    "                    continue\n",
    "                \n",
    "                onset = file['segment'][0] + np.random.random(1) * (file['segment'][1] - file['segment'][0]- WINDOW_WIDTH)\n",
    "                offset = onset + WINDOW_WIDTH\n",
    "                yield class_name, events_folder + '/' + class_name + '/' + file['audio_filename'], float(onset), float(offset)\n",
    "                \n",
    "            if debug:\n",
    "                print(class_name, \"is done, starting from the beginning...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hFzj0LqNYpQ_"
   },
   "outputs": [],
   "source": [
    "def raw_batch_generator(batch_size, phase = 'train', debug=False):\n",
    "    generators = np.array([get_one_class_generator(class_name, phase, debug) for class_name in class_labels])\n",
    "    while True:\n",
    "        random_indices = np.random.randint(0, len(generators), size=batch_size)\n",
    "        yield [gen.__next__() for gen in generators[random_indices]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xhiek2wiYpRC"
   },
   "outputs": [],
   "source": [
    "def create_spectrogram_from_wav_file(wavfile_path, onset, offset):\n",
    "    audio = wavio.read(wavfile_path).data\n",
    "    if audio.shape[1] > 1:\n",
    "        audio = np.sum(audio, axis = 1)\n",
    "    else:\n",
    "        audio = audio.reshape((-1,))\n",
    "    if offset*SAMPLE_RATE > audio.shape[0]:\n",
    "        old = audio.shape\n",
    "        new = (int(SAMPLE_RATE * WINDOW_WIDTH), )\n",
    "        samples = audio[(np.arange(new[0]) % old[0])]\n",
    "    else:\n",
    "        samples = audio[int(onset*SAMPLE_RATE):int(offset*SAMPLE_RATE)]\n",
    "    frequencies, times, spectrogram = signal.spectrogram(samples, SAMPLE_RATE)\n",
    "#    fig=plt.figure(figsize=((5, 5)))\n",
    "#    ax=fig.add_subplot(1,1,1)\n",
    "#    plt.axis('off')\n",
    "#    plt.pcolormesh(times, frequencies, np.log10(spectrogram+1e-20), figure = fig)\n",
    "    return spectrogram\n",
    "\n",
    "def create_spectrogram_from__aug_wav_file(wavfile_path, onset, offset):\n",
    "    audio = wavio.read(wavfile_path).data.astype('float32')\n",
    "    if audio.shape[1] > 1:\n",
    "        audio = np.sum(audio, axis = 1)\n",
    "    else:\n",
    "        audio = audio.reshape((-1,))\n",
    "    \n",
    "    audio_shape = audio.shape[0]\n",
    "    offset_samples = int(offset*SAMPLE_RATE)\n",
    "    onset_samples = int(onset*SAMPLE_RATE)\n",
    "    desired_shape = int(SAMPLE_RATE * WINDOW_WIDTH)\n",
    "    \n",
    "    if offset_samples > audio.shape[0]:\n",
    "        old = audio.shape\n",
    "        new = (int(SAMPLE_RATE * WINDOW_WIDTH), )\n",
    "        samples = audio[(np.arange(new[0]) % old[0])]\n",
    "    else:\n",
    "        samples = audio[onset_samples:offset_samples]\n",
    "        \n",
    "    flow = naf.Sequential([\n",
    "        naa.PitchAug(sampling_rate=SAMPLE_RATE, pitch_factor=(np.random.random() - 0.5) * 10),\n",
    "        naa.SpeedAug(speed_factor=(np.random.random()*0.4 + 0.8)),\n",
    "        naa.ShiftAug(sampling_rate=SAMPLE_RATE, shift_max=samples.shape[0] / (10 * SAMPLE_RATE))\n",
    "        ])\n",
    "    samples = flow.augment(samples)\n",
    "    \n",
    "    if desired_shape > samples.shape[0]:\n",
    "        audio_pad = np.zeros(desired_shape)\n",
    "        audio_pad[:samples.shape[0]] = samples\n",
    "        samples = audio_pad\n",
    "    else:\n",
    "        samples = samples[:desired_shape]\n",
    "        \n",
    "    noise = naa.NoiseAug(np.random.random()*50)\n",
    "    samples = noise.substitute(samples)\n",
    "        \n",
    "    frequencies, times, spectrogram = signal.spectrogram(samples, SAMPLE_RATE)\n",
    "#    fig=plt.figure(figsize=((5, 5)))\n",
    "#    ax=fig.add_subplot(1,1,1)\n",
    "#    plt.axis('off')\n",
    "#    plt.pcolormesh(times, frequencies, np.log10(spectrogram+1e-20), figure = fig)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mt6xKDYzYpRK"
   },
   "outputs": [],
   "source": [
    "def data_and_labels_generator(batch_size, phase = 'train'):\n",
    "    for batch in raw_batch_generator(batch_size, phase):\n",
    "        batch_data = []\n",
    "        batch_labels = []\n",
    "        for wav in batch:          \n",
    "            batch_data.append(create_spectrogram_from_wav_file(wav[1], wav[2], wav[3]))\n",
    "            batch_labels.append(wav[0])\n",
    "        batch_data = np.stack(batch_data, axis=0)\n",
    "        yield batch_data, batch_labels\n",
    "        \n",
    "augmentor = naf.Sequential([\n",
    "            nas.FrequencyMaskingAug(mask_factor=MASK_FACTOR),\n",
    "            nas.FrequencyMaskingAug(mask_factor=MASK_FACTOR),\n",
    "            nas.TimeMaskingAug(mask_factor=MASK_FACTOR), \n",
    "            nas.TimeMaskingAug(mask_factor=MASK_FACTOR)])\n",
    "        \n",
    "def data_and_labels_generator_with_augmentation(batch_size, phase = 'train'):\n",
    "    for batch in raw_batch_generator(batch_size, phase):\n",
    "        batch_data = []\n",
    "        batch_labels = []\n",
    "        for wav in batch:\n",
    "            data = create_spectrogram_from__aug_wav_file(wav[1], wav[2], wav[3])\n",
    "            for s in range(NMB_OF_GENERATED_IMG_PER_IMG):\n",
    "                batch_data.append(augmentor.augment(data))\n",
    "                batch_labels.append(wav[0])\n",
    "        batch_data = np.stack(batch_data, axis=0)\n",
    "        yield batch_data, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-y883wi0YpRS"
   },
   "source": [
    "## Train preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "Kw7tZ14bYpRX",
    "outputId": "3b0ced12-f30d-46ef-bd15-3c1f99051a8e"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8MNkuRxYpRe"
   },
   "outputs": [],
   "source": [
    "# reset graph when you change architecture!\n",
    "def reset_tf_session():\n",
    "    curr_session = tf.get_default_session()\n",
    "    # close current session\n",
    "    if curr_session is not None:\n",
    "        curr_session.close()\n",
    "    # reset graph\n",
    "    K.clear_session()\n",
    "    # create new session\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    s = tf.InteractiveSession(config=config)\n",
    "    K.set_session(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kgxxSKNYYpRh"
   },
   "outputs": [],
   "source": [
    "def train_iterator(batch_size):\n",
    "    for batch in data_and_labels_generator(batch_size, phase = 'train'):\n",
    "        data = batch[0].astype('float32')\n",
    "        data = data +  1e-21\n",
    "        data = np.log10(data)\n",
    "        data =  (((data - np.min(data)) * (1 - (-1))) / (np.max(data) - np.min(data))) + (-1)\n",
    "        data = np.expand_dims(data, -1)\n",
    "        labels = keras.utils.to_categorical(list(map(class_to_idx.get, batch[1])), NUM_CLASSES)\n",
    "        yield data, labels\n",
    "      \n",
    "def train_iterator_with_augmentation(batch_size):\n",
    "    for batch in data_and_labels_generator_with_augmentation(batch_size, phase = 'train'):\n",
    "        data = batch[0].astype('float32')\n",
    "        data = data +  1e-21\n",
    "        data = np.log10(data)\n",
    "        data =  (((data - np.min(data)) * (1 - (-1))) / (np.max(data) - np.min(data))) + (-1)\n",
    "        data = np.expand_dims(data, -1)\n",
    "        labels = keras.utils.to_categorical(list(map(class_to_idx.get, batch[1])), NUM_CLASSES)\n",
    "        yield data, labels\n",
    "      \n",
    "      \n",
    "def val_iterator(batch_size):\n",
    "    for batch in data_and_labels_generator(batch_size, phase = 'val'):\n",
    "        data = batch[0].astype('float32')\n",
    "        data = data +  1e-21\n",
    "        data = np.log10(data)\n",
    "        data =  (((data - np.min(data)) * (1 - (-1))) / (np.max(data) - np.min(data))) + (-1)\n",
    "        data = np.expand_dims(data, -1)\n",
    "        labels = keras.utils.to_categorical(list(map(class_to_idx.get, batch[1])), NUM_CLASSES)\n",
    "        yield data, labels\n",
    "      \n",
    "def val_iterator_with_augmentation(batch_size):\n",
    "    for batch in data_and_labels_generator_with_augmentation(batch_size, phase = 'val'):\n",
    "        data = batch[0].astype('float32')\n",
    "        data = data +  1e-21\n",
    "        data = np.log10(data)\n",
    "        data =  (((data - np.min(data)) * (1 - (-1))) / (np.max(data) - np.min(data))) + (-1)\n",
    "        data = np.expand_dims(data, -1)\n",
    "        labels = keras.utils.to_categorical(list(map(class_to_idx.get, batch[1])), NUM_CLASSES)\n",
    "        yield data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVcCLxQhYpRl"
   },
   "outputs": [],
   "source": [
    "# import necessary building blocks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, GlobalAveragePooling2D, \\\n",
    "    BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAxXE2wcYpRw"
   },
   "outputs": [],
   "source": [
    "from keras.metrics import categorical_crossentropy, categorical_accuracy\n",
    "from keras_metrics import precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lveAw3ifYpR2"
   },
   "outputs": [],
   "source": [
    "# for saving the model after every epoch\n",
    "from keras.models import save_model\n",
    "\n",
    "class ModelSaveCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, file_name):\n",
    "        super(ModelSaveCallback, self).__init__()\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        model_filename = self.file_name.format(epoch)\n",
    "        save_model(self.model, model_filename)\n",
    "        print(\"Model saved in {}\".format(model_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "SMyjjxy7YpR-",
    "outputId": "02b27055-a03d-462b-f526-82b3d03bea9b"
   },
   "outputs": [],
   "source": [
    "GOOGLE_DRIVE_ROOT = GOOGLE_DRIVE_MOUNT + \"/\" + list(filter(lambda x: x[0] != '.', os.listdir(GOOGLE_DRIVE_MOUNT)))[0]\n",
    "print(GOOGLE_DRIVE_ROOT)\n",
    "\n",
    "# will save checkpoints to Google Drive\n",
    "CHECKPOINT_TEMPLATE = GOOGLE_DRIVE_ROOT + \"/colab/Frame_Classification/model_{}\"\n",
    "print(CHECKPOINT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EdCRJBJ9YpSD"
   },
   "source": [
    "# Архитектура"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sF47Pz6g_qF5"
   },
   "outputs": [],
   "source": [
    "def make_model2():\n",
    "   \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=2, padding='same', input_shape=(SPECTROGRAM_HEIGH, SPECTROGRAM_WIDTH, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    ############################################################################\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    ############################################################################\n",
    "    \n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), strides=2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=128, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    ############################################################################\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    ############################################################################\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    ############################################################################\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    ############################################################################\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(3, 3), strides=2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=512, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    ############################################################################\n",
    "    \n",
    "    model.add(Conv2D(filters=1024, kernel_size=(3, 3), strides=2, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(filters=1024, kernel_size=(1, 1), strides=1, padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    ############################################################################  \n",
    "    \n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    \n",
    "    ############################################################################\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 980
    },
    "colab_type": "code",
    "id": "8UjrmAl4YpSJ",
    "outputId": "e42c472d-6bc0-4d04-9e91-2b2e83c534f6"
   },
   "outputs": [],
   "source": [
    "# describe model\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model1()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "b4qkA91mYpSR",
    "outputId": "7e5d6c5d-83d0-4f8a-cb8e-0d52e8b59993"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "STEPS_PER_EPOCH = 100\n",
    "EPOCHS = 100\n",
    "\n",
    "s = reset_tf_session()  # clear default graph\n",
    "model = make_model2()  # define our model\n",
    "\n",
    "# prepare model for fitting (loss, optimizer, etc)\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0),\n",
    "    metrics=[categorical_accuracy, precision(), recall(), f1_score()]\n",
    ")\n",
    "last_finished_epoch = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tzQ8ZOnAYpSV"
   },
   "source": [
    "# Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "yiO7mDQoYpSV",
    "outputId": "f7e04cd1-ac9b-4a8b-fa21-8246010eac42"
   },
   "outputs": [],
   "source": [
    " model.fit_generator(\n",
    "    train_iterator_with_augmentation(BATCH_SIZE), \n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[ModelSaveCallback(CHECKPOINT_TEMPLATE)],\n",
    "    verbose=1,\n",
    "    initial_epoch=last_finished_epoch,\n",
    "    validation_data = val_iterator_with_augmentation(BATCH_SIZE),\n",
    "    validation_steps = 1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Frame_Classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
