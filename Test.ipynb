{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Test.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Glebzok/AudioSegmentation/blob/master/Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo0hdWDrI-xD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "370b501c-63d5-49f2-8e2c-33a0a7c10b20"
      },
      "source": [
        "from google.colab import drive\n",
        "GOOGLE_DRIVE_MOUNT = \"/content/gdrive\"\n",
        "drive.mount(GOOGLE_DRIVE_MOUNT)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPHtLDN1JAnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4b4a67c9-d634-4e58-a5a8-dc0b15d7a118"
      },
      "source": [
        "% cd ..\n",
        "! cp -rf '/content/gdrive/My Drive/colab/Frame_Classification' .\n",
        "% cd Frame_Classification"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n",
            "/Frame_Classification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMu9b7HjI8ff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "e7b30146-104c-4a6c-aff8-e59a2c016c11"
      },
      "source": [
        "! pip install wavio\n",
        "! pip install soundfile\n",
        "! pip install nlpaug\n",
        "! pip install keras-metrics"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wavio\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/98/8bf5ea39a3385cc806ba1146a280a113835e5df3b0ad25ca95eea8352040/wavio-0.0.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from wavio) (1.16.4)\n",
            "Installing collected packages: wavio\n",
            "Successfully installed wavio-0.0.4\n",
            "Collecting soundfile\n",
            "  Downloading https://files.pythonhosted.org/packages/68/64/1191352221e2ec90db7492b4bf0c04fd9d2508de67b3f39cbf093cd6bd86/SoundFile-0.10.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.12.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.19)\n",
            "Installing collected packages: soundfile\n",
            "Successfully installed soundfile-0.10.2\n",
            "Collecting nlpaug\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/63/544d0363c2d4bb88cb32d26d9a320f546beb8403f129f40238f5ef9804b3/nlpaug-0.0.6-py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.1MB/s \n",
            "\u001b[?25hInstalling collected packages: nlpaug\n",
            "Successfully installed nlpaug-0.0.6\n",
            "Collecting keras-metrics\n",
            "  Downloading https://files.pythonhosted.org/packages/32/c9/a87420da8e73de944e63a8e9cdcfb1f03ca31a7c4cdcdbd45d2cdf13275a/keras_metrics-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.6/dist-packages (from keras-metrics) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.16.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.1.5->keras-metrics) (1.3.0)\n",
            "Installing collected packages: keras-metrics\n",
            "Successfully installed keras-metrics-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS2c4p7iI8fs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from core import read_meta_yaml\n",
        "import wave\n",
        "import contextlib\n",
        "import wavio\n",
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import groupby\n",
        "import librosa\n",
        "import nlpaug.flow as naf\n",
        "import nlpaug.augmenter.spectrogram as nas\n",
        "import nlpaug.augmenter.audio as naa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YYt0UvJI8f1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WINDOW_WIDTH = 5e-1 #s\n",
        "HOP_LENGTH = 225\n",
        "SAMPLE_RATE = 44100\n",
        "SPECTROGRAM_HEIGH = 129\n",
        "SPECTROGRAM_WIDTH = int(WINDOW_WIDTH * SAMPLE_RATE / HOP_LENGTH)\n",
        "PROB_TRESHOLD = 0.8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4q74u7yI8gA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_labels = ['clearthroat', 'knock', 'keys', 'bg']\n",
        "NUM_CLASSES = len(class_labels)\n",
        "class_to_idx = {c: idx for idx, c in enumerate(class_labels)}\n",
        "idx_to_class = {class_to_idx[c]: c for c in class_to_idx.keys()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO6hzzRzI8gE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_spectrogram_from_wav_file(wavfile_path, onset, offset):\n",
        "    audio = wavio.read(wavfile_path).data\n",
        "    if audio.shape[1] > 1:\n",
        "        audio = np.sum(audio, axis = 1)\n",
        "    else:\n",
        "        audio = audio.reshape((-1,))\n",
        "    if offset*SAMPLE_RATE > audio.shape[0]:\n",
        "      \n",
        "        old = audio.shape\n",
        "        new = (int(SAMPLE_RATE * WINDOW_WIDTH), )\n",
        "        samples = audio[(np.arange(new[0]) % old[0])]\n",
        "    else:\n",
        "        samples = audio[int(onset*SAMPLE_RATE):int(offset*SAMPLE_RATE)]\n",
        "    frequencies, times, spectrogram = signal.spectrogram(samples, SAMPLE_RATE)\n",
        "#    fig=plt.figure(figsize=((5, 5)))\n",
        "#    ax=fig.add_subplot(1,1,1)\n",
        "#    plt.axis('off')\n",
        "#    plt.pcolormesh(times, frequencies, np.log10(spectrogram+1e-20), figure = fig)\n",
        "    return spectrogram"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqdEjHnbI8gO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a3e7a888-d08f-4b3d-82a7-7f1bd8aca991"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import backend as K"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw-xJAd1I8gT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reset graph when you change architecture!\n",
        "def reset_tf_session():\n",
        "    curr_session = tf.get_default_session()\n",
        "    # close current session\n",
        "    if curr_session is not None:\n",
        "        curr_session.close()\n",
        "    # reset graph\n",
        "    K.clear_session()\n",
        "    # create new session\n",
        "    config = tf.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True\n",
        "    s = tf.InteractiveSession(config=config)\n",
        "    K.set_session(s)\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT1t4LL2I8gZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import necessary building blocks\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, GlobalAveragePooling2D, \\\n",
        "    BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiZ6buuwI8gf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.metrics import categorical_crossentropy, categorical_accuracy\n",
        "from keras_metrics import precision, recall, f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq8UPM86I8gn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_model2():\n",
        "   \n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=2, padding='same', input_shape=(SPECTROGRAM_HEIGH, SPECTROGRAM_WIDTH, 1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    ############################################################################\n",
        "    \n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=64, kernel_size=(1, 1), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=64, kernel_size=(1, 1), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    ############################################################################\n",
        "    \n",
        "    model.add(Conv2D(filters=128, kernel_size=(3, 3), strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=128, kernel_size=(1, 1), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    ############################################################################\n",
        "    \n",
        "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    ############################################################################\n",
        "    \n",
        "    \n",
        "    model.add(Conv2D(filters=256, kernel_size=(3, 3), strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=256, kernel_size=(1, 1), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    ############################################################################\n",
        "    \n",
        "    model.add(Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=512, kernel_size=(1, 1), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=512, kernel_size=(1, 1), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=512, kernel_size=(3, 3), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=512, kernel_size=(1, 1), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    ############################################################################\n",
        "    \n",
        "    model.add(Conv2D(filters=512, kernel_size=(3, 3), strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=512, kernel_size=(1, 1), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    ############################################################################\n",
        "    \n",
        "    model.add(Conv2D(filters=1024, kernel_size=(3, 3), strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(filters=1024, kernel_size=(1, 1), strides=1, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    ############################################################################  \n",
        "    \n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    \n",
        "    ############################################################################\n",
        "\n",
        "    model.add(Dense(1024))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgb4vI5eI8g4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "a5459179-af67-4b77-f965-24777a4925c0"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "\n",
        "s = reset_tf_session()  # clear default graph\n",
        "model = make_model2()  # define our model\n",
        "\n",
        "# prepare model for fitting (loss, optimizer, etc)\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0),\n",
        "    metrics=[categorical_accuracy, precision(), recall(), f1_score()]\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0805 09:41:13.034584 140652845705088 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "W0805 09:41:13.036397 140652845705088 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0805 09:41:13.083085 140652845705088 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0805 09:41:13.149437 140652845705088 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0805 09:41:13.153966 140652845705088 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0805 09:41:13.380136 140652845705088 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0805 09:41:16.455404 140652845705088 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK1tlSBMI8hC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_iterator(batch_size, audio_path):\n",
        "    audio_paths = []\n",
        "    if os.path.isdir(audio_path):\n",
        "        for inp_file in os.listdir(audio_path):\n",
        "            audio_paths += [audio_path + inp_file]\n",
        "    else:\n",
        "        audio_paths += [audio_path] \n",
        "        \n",
        "    audio_paths = [inp_file for inp_file in audio_paths if (inp_file[-4:]  == '.wav')]\n",
        "    \n",
        "    tracks = []\n",
        "\n",
        "    batch_keys = []\n",
        "    batch_data = []\n",
        "    \n",
        "    for j, inp_audio in enumerate(audio_paths):\n",
        "        data = wavio.read(inp_audio).data\n",
        "        \n",
        "        full_segments = (data.shape[0] /  float(SAMPLE_RATE)) // WINDOW_WIDTH\n",
        "        if (data.shape[0] / float(SAMPLE_RATE)) % WINDOW_WIDTH != 0:\n",
        "            full_segments += 1\n",
        "        \n",
        "        segments = []\n",
        "        for i in range(int(full_segments)):\n",
        "            \n",
        "\n",
        "            batch_data.append(create_spectrogram_from_wav_file(inp_audio, i * WINDOW_WIDTH, (i+1)*WINDOW_WIDTH))\n",
        "            batch_keys.append((inp_audio,i))\n",
        "            if len(batch_data) == batch_size:\n",
        "                \n",
        "                batch_data = np.stack(batch_data, axis=0)\n",
        "                batch_data = np.expand_dims(batch_data, -1)\n",
        "                batch_data = batch_data.astype('float32')\n",
        "                batch_data = batch_data +  1e-21\n",
        "                batch_data = np.log10(batch_data)\n",
        "                batch_data =  (((batch_data - np.min(batch_data)) * (1 - (-1))) / float(np.max(batch_data) - np.min(batch_data))) + (-1)\n",
        "              \n",
        "                yield batch_keys, batch_data\n",
        "                batch_keys = []\n",
        "                batch_data = []    \n",
        "   \n",
        "    if batch_data:  # last batch\n",
        "        batch_data = np.stack(batch_data, axis=0)\n",
        "        batch_data = np.expand_dims(batch_data, -1)\n",
        "        batch_data = batch_data.astype('float32')\n",
        "       \n",
        "        batch_data = batch_data +  1e-21\n",
        "        batch_data = np.log10(batch_data)\n",
        "        batch_data =  (((batch_data - np.min(batch_data)) * (1 - (-1))) / float(np.max(batch_data) - np.min(batch_data))) + (-1)\n",
        "\n",
        "        yield batch_keys, batch_data\n",
        "        batch_keys = []\n",
        "        batch_data = [] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07Qgv5umI8hL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(audio_path = './test_audio_folder/'):\n",
        "    colors = ['r', 'g', 'b', 'y']\n",
        "    \n",
        "    keys = []\n",
        "    classes = []\n",
        "    \n",
        "    for batch_keys, batch_data in test_iterator(BATCH_SIZE, audio_path):\n",
        "        keys.append(batch_keys)\n",
        "        probs = model.predict_proba(batch_data, BATCH_SIZE)\n",
        "        prob_argmax = np.argmax(probs, axis=1)\n",
        "        print(prob_argmax)\n",
        "        prob_max = np.max(probs, axis=1)\n",
        "        cs = [c if prob_max[i] > PROB_TRESHOLD else class_to_idx['bg'] for i,c in enumerate(prob_argmax)]\n",
        "        classes.append(cs)\n",
        "\n",
        "    classes = [c for batch in classes for c in batch]\n",
        "    keys = [k for batch in keys for k in batch]\n",
        "    \n",
        "    keys_classes = list(zip(keys, classes))\n",
        "    \n",
        "    keys_classes.sort(key = lambda x : (x[0][0], x[0][1]))\n",
        "    files = [list(g) for k, g in groupby(keys_classes, lambda s: s[0][0].partition('/')[-1])]\n",
        "    for f in files:\n",
        "        filename = f[0][0][0]\n",
        "        window_classes = [i[1] for i in f]\n",
        "        \n",
        "        audio = wavio.read(filename).data\n",
        "        if audio.shape[1] > 1:\n",
        "            audio = np.sum(audio, axis = 1)\n",
        "        else:\n",
        "            audio = audio.reshape((-1,))\n",
        "\n",
        "        plt.figure(figsize=(20,10))\n",
        "        plt.title(filename)\n",
        "        plt.plot(np.linspace(0, audio.shape[0], audio.shape[0]), audio)\n",
        "        \n",
        "        for i, window in enumerate(window_classes):\n",
        "            lb = int(i * WINDOW_WIDTH * SAMPLE_RATE)\n",
        "            rb = int(min(audio.shape[0], (i+1) * WINDOW_WIDTH * SAMPLE_RATE))\n",
        "        \n",
        "            plt.plot(np.linspace(0, audio.shape[0], audio.shape[0])[lb:rb], audio[lb:rb], label = idx_to_class[window], c = colors[window])\n",
        "        \n",
        "        handles, labels = plt.gca().get_legend_handles_labels()\n",
        "        newLabels, newHandles = [], []\n",
        "        for handle, label in zip(handles, labels):\n",
        "            if label not in newLabels:\n",
        "                newLabels.append(label)\n",
        "                newHandles.append(handle)\n",
        "        plt.legend(newHandles, newLabels)\n",
        "        plt.xlabel('time (s)')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bBgnvsooI8hb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('model_1')\n",
        "predict('./test_audio_folder/')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}